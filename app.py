import PyPDF2
import re
import streamlit as st
import tempfile
import time
import matplotlib.pyplot as plt
import seaborn as sns
import requests
import numpy as np
import torch
from sentence_transformers import SentenceTransformer

device = "cpu"  # Force CPU mode for compatibility
model = SentenceTransformer('all-MiniLM-L6-v2', device=device)

print("âœ… Using CPU mode (Streamlit Cloud safe)")
# ğŸ”¹ Replace with your actual API Keys
import streamlit as st
import requests

# âœ… Get API keys securely from Streamlit secrets
GROQ_API_KEY = st.secrets["GROQ_API_KEY"]
GROQ_API_URL = st.secrets["GROQ_API_URL"]

OPENROUTER_API_KEY = st.secrets["OPENROUTER_API_KEY"]
OPENROUTER_API_URL = st.secrets["OPENROUTER_API_URL"]

HF_API_KEY = st.secrets["HF_API_KEY"]
HF_API_URL = st.secrets["HF_API_URL"]

MODEL_NAME = "llama3-70b-8192"  # Default Groq model

def extract_text_from_pdf(uploaded_file):
    """Extracts and cleans text from an uploaded PDF resume."""
    text = ""
    pdf_reader = PyPDF2.PdfReader(uploaded_file)
    for page in pdf_reader.pages:
        page_text = page.extract_text()
        if page_text:
            text += page_text + "\n"
    return preprocess_text(text.strip())

def preprocess_text(text):
    """Cleans and preprocesses text by removing special characters and extra spaces."""
    text = text.lower().strip()
    text = re.sub(r'\s+', ' ', text)  # Normalize spaces
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)  # Remove special characters
    return text

def analyze_match(resume_text, job_description):
    """Analyzes resume vs job description using APIs, with fallback to local processing."""
    max_length = 3000  # Truncate long inputs
    truncated_resume = resume_text[:max_length]
    truncated_jd = job_description[:max_length]

    prompt = f"""
    Analyze the match between this resume and job description.
    Consider key skills, experience requirements, and qualifications.
    Respond ONLY with a percentage match score between 0-100 without any additional text.

    Resume: {truncated_resume}
    Job Description: {truncated_jd}
    Match Score: """

    def call_api(api_url, api_key, headers):
        """Helper function to call an API and parse response."""
        try:
            payload = {
                "model": MODEL_NAME,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.2,
                "max_tokens": 10
            }
            response = requests.post(api_url, headers=headers, json=payload)

            if response.status_code != 200:
                raise Exception(f"API Error: {response.text}")

            response_text = response.json()['choices'][0]['message']['content'].strip()
            match = re.search(r'\b(\d{1,3})\b', response_text)

            if match:
                return max(0, min(100, float(match.group(1))))  # Ensure score is 0-100
        except Exception as e:
            st.warning(f"âŒ Failed to use API {api_url}: {e}")
            return None

    # Try APIs in order
    for api_url, api_key in [(GROQ_API_URL, GROQ_API_KEY), (OPENROUTER_API_URL, OPENROUTER_API_KEY), (HF_API_URL, HF_API_KEY)]:
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        match_score = call_api(api_url, api_key, headers)
        if match_score is not None:
            return match_score

    # Final Fallback: Local SentenceTransformer model
    st.warning("ğŸš¨ All APIs failed. Using local model for analysis.")
    embeddings = model.encode([resume_text, job_description], convert_to_tensor=True)
    cosine_similarity = util.cos_sim(embeddings[0], embeddings[1]).item()
    return cosine_similarity * 100

def generate_resume_improvement_suggestions(resume_text, job_description):
    """Generates **detailed** resume improvement suggestions using AI."""
    prompt = f"""
    You are an expert HR consultant. Analyze this resume based on the job description and provide the following:
    1ï¸âƒ£ Key **skills missing** from the resume that should be added.
    2ï¸âƒ£ If the resume is **ATS-friendly** or needs formatting improvements.
    3ï¸âƒ£ **Additional projects** or work experience that can enhance alignment.
    4ï¸âƒ£ **Specific phrases** or keywords to improve the resume.

    Resume: {resume_text[:3000]}
    Job Description: {job_description[:3000]}
    """

    headers = {"Authorization": f"Bearer {GROQ_API_KEY}", "Content-Type": "application/json"}
    
    try:
        payload = {"model": MODEL_NAME, "messages": [{"role": "user", "content": prompt}], "temperature": 0.3, "max_tokens": 300}
        response = requests.post(GROQ_API_URL, headers=headers, json=payload)

        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
        else:
            return "âš ï¸ Failed to generate detailed recommendations. Try refining your resume manually."
    except Exception as e:
        return f"âš ï¸ Error generating resume recommendations: {e}"

# Streamlit UI Setup
st.set_page_config(page_title="AI Resume & Job Matcher", page_icon="ğŸ“„", layout="centered")
st.image("resume.jpeg", use_column_width=True)

st.title("ğŸ“„ AI Resume & Job Matcher")
st.write("### Upload your resume & job description to see how well they match!")

# File Upload
uploaded_file = st.file_uploader("ğŸ“‚ Upload your resume (PDF)", type=["pdf"])
resume_text = ""

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False) as temp_file:
        temp_file.write(uploaded_file.read())
        resume_text = extract_text_from_pdf(temp_file.name)
    st.success("âœ… Resume uploaded successfully!")

# Job Description Input
job_description = st.text_area("ğŸ“ Paste the job description here:", height=200, placeholder="Enter the job description...")

if st.button("Analyze Match âœ…"):
    if resume_text and job_description:
        with st.spinner("ğŸ” Analyzing the match... Please wait."):
            time.sleep(2)
            processed_resume = preprocess_text(resume_text)
            processed_job = preprocess_text(job_description)
            
            try:
                match_score = analyze_match(processed_resume, processed_job)
                recommendations = generate_resume_improvement_suggestions(processed_resume, processed_job)
            except Exception as e:
                st.error(f"Failed to analyze match: {e}")
                st.stop()
        
        st.success(f"ğŸ”¥ Match Score: {match_score:.2f}%")
        st.progress(match_score / 100)
        
        if match_score > 80:
            st.balloons()
            st.write("ğŸ‰ Excellent match! Your resume is highly aligned with this job.")
        elif match_score > 50:
            st.write("ğŸ‘ Good match! Consider fine-tuning your resume for a better fit.")
        else:
            st.write("âš ï¸ Weak match. Modify your resume for better alignment.")
        
        st.write("### ğŸ“Š Resume Analysis Insights")
        labels = ["Match", "Missing Skills"]
        values = [match_score, 100 - match_score]
        fig, ax = plt.subplots()
        ax.pie(values, labels=labels, autopct='%1.1f%%', colors=['#4CAF50', '#FF5252'], startangle=140)
        st.pyplot(fig)

        st.write("### ğŸ“Œ **Detailed Resume Recommendations**")
        st.write(recommendations)
    else:
        st.warning("âš ï¸ Please upload a resume and enter a job description!")
